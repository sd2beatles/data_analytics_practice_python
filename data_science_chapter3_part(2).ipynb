{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "  state/region     ages  year  population\n",
      "0           AL  under18  2012   1117489.0\n",
      "1           AL    total  2012   4817528.0\n",
      "2           AL  under18  2010   1130966.0\n",
      "3           AL    total  2010   4785570.0\n",
      "4           AL  under18  2011   1125763.0\n",
      "        state  area (sq. mi)\n",
      "0     Alabama          52423\n",
      "1      Alaska         656425\n",
      "2     Arizona         114006\n",
      "3    Arkansas          53182\n",
      "4  California         163707\n",
      "        state abbreviation\n",
      "0     Alabama           AL\n",
      "1      Alaska           AK\n",
      "2     Arizona           AZ\n",
      "3    Arkansas           AR\n",
      "4  California           CA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%xmode Plain\n",
    "pop=pd.read_csv(r\"C:\\Users\\DAVID SEO\\Desktop\\state-population.txt\")\n",
    "area=pd.read_csv(r\"C:\\Users\\DAVID SEO\\Desktop\\state-areas.txt\")\n",
    "abbrevs=pd.read_csv(r\"C:\\Users\\DAVID SEO\\Desktop\\state-abbrevs.txt\")\n",
    "\n",
    "print(pop.head())\n",
    "print(area.head())\n",
    "print(abbrevs.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state/region    False\n",
      "state            True\n",
      "ages            False\n",
      "year            False\n",
      "population       True\n",
      "dtype: bool\n",
      "     state/region state     ages  year  population\n",
      "2448           PR   NaN  under18  1990         NaN\n",
      "2449           PR   NaN    total  1990         NaN\n",
      "2450           PR   NaN    total  1991         NaN\n",
      "2451           PR   NaN  under18  1991         NaN\n",
      "2452           PR   NaN    total  1993         NaN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state/region</th>\n",
       "      <th>state</th>\n",
       "      <th>ages</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>area (sq. mi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>under18</td>\n",
       "      <td>2012</td>\n",
       "      <td>1117489.0</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>total</td>\n",
       "      <td>2012</td>\n",
       "      <td>4817528.0</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>under18</td>\n",
       "      <td>2010</td>\n",
       "      <td>1130966.0</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>total</td>\n",
       "      <td>2010</td>\n",
       "      <td>4785570.0</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>under18</td>\n",
       "      <td>2011</td>\n",
       "      <td>1125763.0</td>\n",
       "      <td>52423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state/region    state     ages  year  population  area (sq. mi)\n",
       "0           AL  Alabama  under18  2012   1117489.0        52423.0\n",
       "1           AL  Alabama    total  2012   4817528.0        52423.0\n",
       "2           AL  Alabama  under18  2010   1130966.0        52423.0\n",
       "3           AL  Alabama    total  2010   4785570.0        52423.0\n",
       "4           AL  Alabama  under18  2011   1125763.0        52423.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged=pop.merge(abbrevs,how=\"outer\",left_on=\"state/region\",right_on=\"abbreviation\").drop(\"abbreviation\",axis=1)\n",
    "cols=['state/region','state', 'ages', 'year', 'population' ]\n",
    "merged=pd.DataFrame(merged,columns=cols)\n",
    "\n",
    "'''\n",
    "Before merging another table. It is a good custom to double-check whether there were any mismatches here,\n",
    "which we can do by lookinf for rows with nulls.\n",
    "'''\n",
    "print(merged.isnull().any())\n",
    "\n",
    "#This indicates that some of population is null.Note that what we are aming to achieve here is density. \n",
    "#Therefore, we should pay attention first to one of elements essential for its calculation.\n",
    "print(merged[merged.population.isnull()].head())\n",
    "print()\n",
    "merged[merged.population.isnull()].tail()\n",
    "\n",
    "'''\n",
    "It appear that null values are from PR prior to the year 2000.This is more likely the data not\n",
    "being available from the original source.\n",
    "\n",
    "Secondl, we also realizes that some of the state entries are also null, which means there are no \n",
    "correspongind entry in the abbrevs key. Let's look at which state lacks this match. \n",
    "'''\n",
    "\n",
    "#Finding the state which contains null values and its corresponding entries in state/region\n",
    "merged.loc[merged.state.isnull(),\"state/region\"].unique()\n",
    "\n",
    "'''\n",
    "Let's take the code in peices. \n",
    "1)merged.state.isnull() returns True if there is null or False if there is a entry. \n",
    "2)merged.loc[merged.state.isnull()] returns all the entries if merged.state.isnull() ==True.\n",
    "3)We want to narrow our scope to the column of 'state.region' \n",
    "=>merged.loc[merged.state.isnull(),state.region]\n",
    "4).unique returns only the unique element \n",
    "\n",
    "Before inference, we should be already aware that th state section comes from abbrevs data and state/\n",
    "region is from population. \n",
    "\n",
    "We can infer that the population data  includes state entries for PR and USA while abbreves does not \n",
    "have those entries. We canf fix these quickly by filling in appropriate entires\n",
    "'''\n",
    "merged.loc[merged[\"state/region\"]==\"PR\",\"state\"]=\"Puerto Rico\"\n",
    "merged.loc[merged[\"state/region\"]==\"USA\",\"state\"]=\"United States\"\n",
    "\n",
    "# we are now joing the merged with area using a state as a key \n",
    "final=merged.merge(area,on=\"state\",how=\"left\")\n",
    "final.isnull().any()\n",
    "\n",
    "#From the output, we are aware that threre are some missing entries in area.Let's see which region lacks this inforamtion \n",
    "#Also notice from the last section, we have already checked that some information  regarding population is absent prior to year 2012\n",
    "final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state/region     False\n",
       "state            False\n",
       "ages             False\n",
       "year             False\n",
       "population       False\n",
       "area (sq. mi)    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.loc[final[\"area (sq. mi)\"].isnull(),\"state\"].unique()\n",
    "'''\n",
    "The result shows that the DataFrame does not contain the area of the United States as a whole. We could insert the appropriate value\n",
    "(eg using the sum of all state areas) but in this case we will just drop the null values beacuse the population density of\n",
    "the Entire United States is not relevant to our current analysis. \n",
    "'''\n",
    "final.dropna(inplace=True)\n",
    "final.isnull().any() #dobule check if all NaN has been removed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ec65ddefcbed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthe\u001b[0m \u001b[0myear\u001b[0m \u001b[1;36m2010\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mWe\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0mquickly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m '''\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#firt chekc the elemtns of ages : array(['under18', 'total'], dtype=object)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#to give a full information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Aim: rank US states and territories by their 2010 population density.\n",
    "\n",
    "Now, we have all  the data we need. To answer the quetion of interest, let's first select the protion of data correspoding with\n",
    "the year 2010 and the total population. We will use the query() function to do quickly \n",
    "'''\n",
    "final.ages.unique() #firt chekc the elemtns of ages : array(['under18', 'total'], dtype=object)\n",
    "\n",
    "#to give a full information \n",
    "data2010=final.query(\"year==2010 & ages== 'total'\")\n",
    "data2010=data2010.set_index(\"state\")\n",
    "data2010.head()\n",
    "data2010[\"density\"]=data2010[\"population\"]/data2010[\"area (sq. mi)\"]\n",
    "data2010.sort_values(ascending=False,inplace=True,by=\"density\") \n",
    "\n",
    "#to giva a partial infromation \n",
    "density=data2010[\"population\"]/data2010[\"area (sq. mi)\"]\n",
    "density.sort_values(ascending=False,inplace=True)\n",
    "density.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data\n",
      "0   A     0\n",
      "1   B     1\n",
      "2   C     2\n",
      "3   A     3\n",
      "4   B     4\n",
      "5   C     5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data\n",
       "key      \n",
       "A       3\n",
       "B       5\n",
       "C       7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "planets=sns.load_dataset(\"planets\")\n",
    "'''\n",
    "Method describe() computes several common aggregates fro each columns and returns the result \n",
    "This gives us some insights on the overall properties of a dataset. For example, if you see in the year\n",
    "colum that alhtough exoplanets were first discovered as far back as 1989, half of all known exoplnets\n",
    " were not discovered until 2010 or after. \n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Aggregation / Description\n",
    "count()      total number of items\n",
    "first(),last()   first and last items\n",
    "mean,median()  mean and median\n",
    "min(),max()  minimum and maximum\n",
    "std(),var()   standard deviation and variance\n",
    "mad()          mean absolute value\n",
    "prod()       product of all items\n",
    "sum()        sum of all items \n",
    "\n",
    "These are all methods of DataFrame and Series objects\n",
    "These are not enough. The next level of data summarization is the groupby oepration, which allows you to\n",
    "quickly and efficiently compute aggreates on the subsets of data \n",
    "'''\n",
    "\n",
    "\n",
    "###Groupby:Split,Apply,Combine \n",
    "\n",
    "\n",
    "'''\n",
    "- The split step invovles breaking up and grouping a DataFrame depending on the value of specific key\n",
    "- The apply step invovles computing some function, usually an aggregate,transformation,or filtering,within\n",
    "  the individual group\n",
    "- The combine invovles merging the results of these operations in a output array \n",
    "\n",
    "\n",
    "While we could certainly do this manually using some combination of the masking,\n",
    "aggregation, and merging commands covered earlier, it’s important to realize that the\n",
    "intermediate splits do not need to be explicitly instantiated. Rather, the GroupBy can\n",
    "(often) do this in a single pass over the data, updating the sum, mean, count, min, or\n",
    "other aggregate for each group along the way.\n",
    "'''\n",
    "\n",
    "df=pd.DataFrame({\"key\":['A','B','C','A','B','C'],\"data\":range(6)})\n",
    "print(df)\n",
    "\n",
    "#first-taks: We can compute the most basic split-apply-combine operation with the groupby()\n",
    "#method of DataFrames, passing the name of the desired key column:\n",
    "\n",
    "df.groupby(\"key\")\n",
    "'''\n",
    "that what is returned is not a set of DataFrames, but a DataFrameGroupBy\n",
    "object.The actual compuation would not appear until the aggreagtion is applied. \n",
    "'''\n",
    "df.groupby(\"key\").sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'planets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1eeec3281520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;36m1\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mindexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplanets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# returns a statistical summary of each column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplanets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"method\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"orbital_period\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# we have selected a Series group from original group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                             \u001b[1;31m#by reference to its column name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'planets' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "method 1 column indexing \n",
    "'''\n",
    "planets.describe() # returns a statistical summary of each column\n",
    "planets.groupby(\"method\")[\"orbital_period\"] # we have selected a Series group from original group \n",
    "                                            #by reference to its column name\n",
    "#No computation would not occur until we call some aggregate on the object\n",
    "planets.groupby(\"method\")[\"orbital_period\"].median() \n",
    "\n",
    "'''\n",
    "mtehod 2 iteration over groups. \n",
    "The groupby objects also provieds a direct iteration over the groups returing each group as a Series or\n",
    "DataFrame\n",
    "'''\n",
    "for (method,group) in planets.groupby('method'): # method 는  iteration group group은 데이터프레임\n",
    "    print(\"{0:30s}shape={1}\".format(method,group.shape))\n",
    "\n",
    "'''\n",
    "Method 3 Dispatch Methods\n",
    ":Any method not explicitly implemented by pandas would be passed througha and called on the group. \n",
    "(현재까지는 aggregation function을 사용하지 않았다면 그저 내부적으로 그룹별로 묶어서 전달된다고 이해)\n",
    "Notice these methods are applied to each individual group and the results are combined within Groupby \n",
    "and returned. \n",
    "'''\n",
    "planets.groupby(\"method\")[\"year\"].describe().unstack()\n",
    "\n",
    "'''\n",
    "method 4 aggreagate,filter,transform,appliy ** higly important concept !!\n",
    "'''\n",
    "rng=np.random.RandomState(0)\n",
    "df=pd.DataFrame({\"key\":['A','B','C','A','B','C'],\n",
    "                \"data1\":range(6),\n",
    "                \"data2\":rng.randint(0,10,6)},\n",
    "               columns=['key','data1','data2'])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n",
      "  key  data1  data2\n",
      "0   A      0      5\n",
      "1   B      1      0\n",
      "2   C      2      3\n",
      "3   A      3      3\n",
      "4   B      4      7\n",
      "5   C      5      9\n",
      "       data1     data2\n",
      "key                   \n",
      "A    2.12132  1.414214\n",
      "B    2.12132  4.949747\n",
      "C    2.12132  4.242641\n",
      "  key  data1  data2\n",
      "1   B      1      0\n",
      "2   C      2      3\n",
      "4   B      4      7\n",
      "5   C      5      9\n",
      "  key  data1  data2\n",
      "0   A      0      5\n",
      "1   B      1      0\n",
      "2   C      2      3\n",
      "3   A      3      3\n",
      "4   B      4      7\n",
      "5   C      5      9\n",
      "  key     data1  data2\n",
      "0   A  0.000000      5\n",
      "1   B  0.142857      0\n",
      "2   C  0.166667      3\n",
      "3   A  0.375000      3\n",
      "4   B  0.571429      7\n",
      "5   C  0.416667      9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%xmode Plain\n",
    "planets=sns.load_dataset(\"planets\")\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "'data1': range(6),\n",
    "'data2': rng.randint(0, 10, 6)},\n",
    "columns = ['key', 'data1', 'data2'])\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "method 4 1) aggreagate \n",
    "aggregate This takes a list form and compute all at once. \n",
    "'''\n",
    "df.groupby('key').aggregate(['min',np.median,max])\n",
    "\n",
    "\n",
    "'''\n",
    "method 5 filter operation\n",
    "drop data based on the group properties\n",
    "'''\n",
    "def filter_func(x):\n",
    "    return x['data2'].std()>4 \n",
    "\n",
    "print(df)\n",
    "print(df.groupby('key').std())\n",
    "print(df.groupby('key').filter(filter_func))\n",
    "\n",
    "'''\n",
    "The filter() function should return a Boolean value specifying whether the group\n",
    "passes the filtering.\n",
    "'''\n",
    "def filter_func(x):\n",
    "    if x>50:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data=planets.loc[planets.method==\"Radial Velocity\",\"distance\"]\n",
    "f=filter(filter_func,data)\n",
    "result=pd.Series(f)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "method 6 transformation\n",
    "transformation can return some transfomred version of the full data to recombine.\n",
    "'''\n",
    "\n",
    "planets.groupby(\"method\").transform(lambda x:x-x.mean())\n",
    "import copy\n",
    "final=copy.copy(planets)\n",
    "final[\"distance\"]=final.groupby(\"method\")[\"distance\"].transform(lambda x:x-x.mean())\n",
    "final[final.distance>0]\n",
    "\n",
    "'''\n",
    "method 7 apply method \n",
    "The apply() method lets you apply an arbitrary function to the\n",
    "group results.\n",
    "'''\n",
    "def norm_by_data2(x):\n",
    "    x[\"data1\"]/=x[\"data2\"].sum()\n",
    "    return x\n",
    "\n",
    "\n",
    "print(df);print(df.groupby(\"key\").apply(norm_by_data2))\n",
    "\n",
    "\n",
    "test=copy.copy(planets)\n",
    "def norma_data(x):\n",
    "    x[\"distance\"]=(x[\"distance\"]-x[\"distance\"].mean())/x[\"distance\"].std()\n",
    "    return x\n",
    "\n",
    "test.groupby(\"method\").apply(norma_data)\n",
    "\n",
    "#page 168\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     data1  data2\n",
      "key              \n",
      "A        0      5\n",
      "B        1      0\n",
      "C        2      3\n",
      "A        3      3\n",
      "B        4      7\n",
      "C        5      9\n",
      "   data1  data2\n",
      "a    1.5    4.0\n",
      "b    2.5    3.5\n",
      "c    3.5    6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>America</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <th>British</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <th>China</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data1  data2\n",
       "a America    1.5    4.0\n",
       "b British    2.5    3.5\n",
       "c China      3.5    6.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 8 A list, array, series, or index providing the grouping keys.\n",
    "df.groupby(df[\"key\"]).mean() # a series providing the grouping keys:verbose way\n",
    "df.groupby(\"key\").mean()# simple way we have kept using \n",
    "\n",
    "\n",
    "# method 9 A dictionary or series mapping index to group.\n",
    "df2=df.set_index(\"key\")\n",
    "mapping={\"A\":'America',\"B\":\"British\",\"C\":\"China\"}\n",
    "df2.groupby(mapping).sum()\n",
    "\n",
    "#method 10 Any Python function.\n",
    "print(df2)\n",
    "print(df2.groupby(str.lower).mean())\n",
    "\n",
    "#method 11 A list of valid keys.\n",
    "df2.groupby([str.lower,mapping]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decade</th>\n",
       "      <th>1980s</th>\n",
       "      <th>1990s</th>\n",
       "      <th>2000s</th>\n",
       "      <th>2010s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Astrometry</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eclipse Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microlensing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital Brightness Modulation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsar Timing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulsation Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radial Velocity</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transit Timing Variations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "decade                         1980s  1990s  2000s  2010s\n",
       "method                                                   \n",
       "Astrometry                       0.0    0.0    0.0    2.0\n",
       "Eclipse Timing Variations        0.0    0.0    5.0   10.0\n",
       "Imaging                          0.0    0.0   29.0   21.0\n",
       "Microlensing                     0.0    0.0   12.0   15.0\n",
       "Orbital Brightness Modulation    0.0    0.0    0.0    5.0\n",
       "Pulsar Timing                    0.0    9.0    1.0    1.0\n",
       "Pulsation Timing Variations      0.0    0.0    1.0    0.0\n",
       "Radial Velocity                  1.0   52.0  475.0  424.0\n",
       "Transit                          0.0    0.0   64.0  712.0\n",
       "Transit Timing Variations        0.0    0.0    0.0    9.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decade=10*(planets[\"year\"]//10)\n",
    "decade=decade.astype(str)+'s'\n",
    "decade.name=\"decade\"\n",
    "planets.groupby([\"method\",decade])[\"number\"].sum().unstack(\"decade\").fillna(0)\n",
    "#page 169"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
